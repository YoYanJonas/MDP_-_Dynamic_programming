{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 2, Value Iteration for robot routing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Younes Shafiee 40108194"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this file, we try to solve the task and interpret the required part of homework.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Goal = [6,0]\n",
    "gamma= 0.9\n",
    "iteration_Policy_Evalution = 1000\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def membership(main_array, checking_array):\n",
    "    tempx=[]\n",
    "    indexes=[]\n",
    "    t=0\n",
    "    for i in main_array:\n",
    "        if (checking_array == i).all():\n",
    "            tempx.append(i)\n",
    "            indexes.append(t)\n",
    "        t+=1\n",
    "    return tempx, indexes \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Enviroment(AllStates, State, Action, Goal ):\n",
    "\n",
    "    Row= State[0]\n",
    "    Col= State[1]\n",
    "\n",
    "    RowV= Action[0]\n",
    "    ColV= Action[1]\n",
    "\n",
    "    newRow= Row + RowV\n",
    "    newCol= Col+ ColV\n",
    "\n",
    "    NewState= [newRow, newCol]\n",
    "\n",
    "    _, indexes= membership(AllStates, NewState)\n",
    "    \n",
    "    \n",
    "    if indexes != []:\n",
    "        if NewState == Goal:\n",
    "            Reward= 10\n",
    "        else:\n",
    "            Reward= -1\n",
    "    else:\n",
    "        NewState= State\n",
    "        Reward= -10\n",
    "\n",
    "            \n",
    "\n",
    "    return NewState , Reward\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolicyEvaluation(AllStates, V, AllActions, Policy, Goal, gamma):\n",
    "    \n",
    "    # nStates= len(AllStates)\n",
    "    # nActions= len(AllActions)\n",
    "\n",
    "    for indexState,state in enumerate(AllStates):\n",
    "    \n",
    "        sum = 0\n",
    "\n",
    "        if (state==Goal).all():\n",
    "            continue\n",
    "        \n",
    "        for indexAction, action in enumerate(AllActions):\n",
    "            NewState, Reward = Enviroment(AllStates, state, action, Goal )\n",
    "            _,index_of_next_state=membership(AllStates,NewState)\n",
    "            # print(state,idx, action, AllStates[idx])\n",
    "            # print(\"\\n\")\n",
    "            sum= sum + Policy[indexAction]*(Reward+gamma*V[index_of_next_state])\n",
    "\n",
    "        V[indexState]= sum\n",
    "    \n",
    "    \n",
    "    return V\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ValueIteration(V, AllStates, AllActions, Goal, gamma):\n",
    "\n",
    "    # _,idx_temp=membership(AllStates, Goal)\n",
    "    # newAllState=np.copy(AllStates)\n",
    "    # newAllState=np.delete(newAllState,idx_temp[0], axis=0) ## Remove goal state for not looping\n",
    "\n",
    "    \n",
    "    for indexState,state in enumerate(AllStates):\n",
    "        \n",
    "        Arbiter_Vector=np.zeros((len(AllActions), 1))\n",
    "\n",
    "        if (state==Goal).all():\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        for indexAction, action in enumerate(AllActions):\n",
    "            NewState, Reward = Enviroment(AllStates, state, action, Goal )\n",
    "            _,index_of_next_state=membership(AllStates,NewState)\n",
    "            # print(state,idx, action, AllStates[idx])\n",
    "            # print(\"\\n\")\n",
    "            Arbiter_Vector[indexAction]= Reward+gamma*V[index_of_next_state[0]]\n",
    "\n",
    "        V[indexState]= np.amax(Arbiter_Vector)\n",
    "          \n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "     \n",
    "    return V\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Improvement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PolicyImprovement(V, AllStates, AllActions, Goal, gamma):\n",
    "\n",
    "     Policy= np.zeros((len(AllStates),1))\n",
    "\n",
    "\n",
    "     for indexState,state in enumerate(AllStates):\n",
    "        \n",
    "        Arbiter_Vector=np.zeros((len(AllActions), 1))\n",
    "\n",
    "        if (state==Goal).all():\n",
    "            continue\n",
    "        \n",
    "        for indexAction, action in enumerate(AllActions):\n",
    "            NewState, Reward = Enviroment(AllStates, state, action, Goal )\n",
    "            _,index_of_next_state=membership(AllStates,NewState)\n",
    "            # print(state,idx, action, AllStates[idx])\n",
    "            # print(\"\\n\")\n",
    "            Arbiter_Vector[indexAction]= Reward+gamma*V[index_of_next_state[0]]\n",
    "\n",
    "        temp= np.where(Arbiter_Vector==np.amax(Arbiter_Vector))[0]\n",
    "        index_of_max_action= temp[np.random.randint(len(temp))]\n",
    "        Policy[indexState]= int(index_of_max_action)\n",
    "          \n",
    "        \n",
    "\n",
    "\n",
    "     \n",
    "     return Policy\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlaneSize = (7,5)\n",
    "\n",
    "Plane= np.ones(PlaneSize)\n",
    "Plane[[2,5],0]=0\n",
    "# Plane[5,0]=0\n",
    "Plane[[2,3,5],1]=0\n",
    "# Plane[3,1]=0\n",
    "# Plane[5,1]=0\n",
    "Plane[1,2]=0\n",
    "Plane[[1,3,4],3]=0\n",
    "# Plane[3,3]=0\n",
    "# Plane[4,3]=0\n",
    "Plane[[3,4,5,6],4]=0\n",
    "# Plane[4,4]=0\n",
    "# Plane[5,4]=0\n",
    "# Plane[6,4]=0\n",
    "\n",
    "# print(Plane)\n",
    "\n",
    "\n",
    "\n",
    "# plt.matshow(Plane)\n",
    "\n",
    "AllStates=np.asarray(list(zip(*np.where(Plane == 1)))) \n",
    "nStates= len(AllStates)\n",
    "\n",
    "\n",
    "AllActions= np.array([[1,0], [-1,0], [0,1], [0,-1]])\n",
    "nActions= len(AllActions)\n",
    "\n",
    "# print(Enviroment(AllStates, [3,0], [0,1], Goal ))\n",
    "\n",
    "Policy =0.25*np.ones((4,1))\n",
    "\n",
    "\n",
    "V=np.zeros((nStates,1))\n",
    "\n",
    "\n",
    "\n",
    "for k in range(1, iteration_Policy_Evalution):\n",
    "    v= V\n",
    "    V= PolicyEvaluation(AllStates, V, AllActions, Policy, Goal, gamma)\n",
    "    # print(k)\n",
    "\n",
    "    # if np.linalg.norm(V-v, 1) < 0.0001:\n",
    "        # break\n",
    "\n",
    "# print(V, \"\\n\", AllStates)\n",
    "\n",
    "Policy=PolicyImprovement(V, AllStates, AllActions, Goal, gamma)\n",
    "print(AllStates, \"\\n \\n\" ,Policy, \"\\n \\n\" , AllActions)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground For Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlaneSize = (7,5)\n",
    "\n",
    "Plane= np.ones(PlaneSize)\n",
    "Plane[[2,5],0]=0\n",
    "# Plane[5,0]=0\n",
    "Plane[[2,3,5],1]=0\n",
    "# Plane[3,1]=0\n",
    "# Plane[5,1]=0\n",
    "Plane[1,2]=0\n",
    "Plane[[1,3,4],3]=0\n",
    "# Plane[3,3]=0\n",
    "# Plane[4,3]=0\n",
    "Plane[[3,4,5,6],4]=0\n",
    "# Plane[4,4]=0\n",
    "# Plane[5,4]=0\n",
    "# Plane[6,4]=0\n",
    "\n",
    "# print(Plane)\n",
    "\n",
    "\n",
    "\n",
    "# plt.matshow(Plane)\n",
    "\n",
    "AllStates=np.asarray(list(zip(*np.where(Plane == 1)))) \n",
    "nStates= len(AllStates)\n",
    "\n",
    "\n",
    "AllActions= np.array([[1,0], [-1,0], [0,1], [0,-1]])\n",
    "nActions= len(AllActions)\n",
    "\n",
    "# print(Enviroment(AllStates, [3,0], [0,1], Goal ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "V=np.zeros((nStates,1))\n",
    "\n",
    "\n",
    "### VALUE Iteration\n",
    "for k in range(1, iteration_Policy_Evalution):\n",
    "    v= np.copy(V)\n",
    "    V= ValueIteration(V, AllStates, AllActions, Goal, gamma)\n",
    "    # print(k)\n",
    "\n",
    "    if ((np.squeeze(V)-np.squeeze(v)) < 0.00000000001).all():\n",
    "        print(f\"after {k} iteration termination occured\")\n",
    "        break\n",
    "\n",
    "print(\"See the V and All states. \\n\")\n",
    "print(V, \"\\n\", AllStates)\n",
    "\n",
    "Policy=PolicyImprovement(V, AllStates, AllActions, Goal, gamma)\n",
    "\n",
    "print(\"See Policy and other arrays.\")\n",
    "print(AllStates, \"\\n \\n\" ,Policy, \"\\n \\n\" , AllActions)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episode generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Episode_generator(Plane, AllStates, AllActions, Policy, Goal, initialState ):\n",
    "\n",
    "    \n",
    "    isFinalState=False\n",
    "    timeStep=0\n",
    "    States=[initialState]\n",
    "    action_array=[]\n",
    "    reward_array=[]\n",
    "    while True:\n",
    "\n",
    "\n",
    "        if (States[timeStep]==Goal):\n",
    "            isFinalState = True\n",
    "\n",
    "        if isFinalState== True:\n",
    "\n",
    "            Plane2=np.copy(Plane)\n",
    "            state=States[timeStep]\n",
    "            # Plane2[next_state[0],next_state[1]]=3 #for different color\n",
    "            Plane2[Goal[0], Goal[1]]=7 #for different color\n",
    "            plt.matshow(Plane2)\n",
    "            plt.savefig(f\"./value_iteration//{timeStep}.png\")\n",
    "            plt.close()\n",
    "            \n",
    "            \n",
    "\n",
    "            break\n",
    "    \n",
    "        Plane2=np.copy(Plane)\n",
    "        state=States[timeStep]\n",
    "        Plane2[state[0],state[1]]=3 #for different color\n",
    "        Plane2[Goal[0], Goal[1]]=6 #for different color\n",
    "        plt.matshow(Plane2)\n",
    "        plt.savefig(f\"./value_iteration/{timeStep}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "        _,idxOfState=membership(AllStates, state)\n",
    "        idxOfAction=int(Policy[idxOfState[0]][0])\n",
    "        action= AllActions[idxOfAction]\n",
    "        next_state, reward=Enviroment(AllStates, state, action, Goal)\n",
    "\n",
    "        States.append(next_state)\n",
    "        action_array.append(action)\n",
    "        reward_array.append(reward)       \n",
    "\n",
    "        timeStep=timeStep+1\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    return States, action_array, reward_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions, rewards=Episode_generator(Plane, AllStates, AllActions, Policy, Goal, [0,0] )\n",
    "print(states, \"\\n \\n\", actions, \"\\n \\n\", rewards, \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
